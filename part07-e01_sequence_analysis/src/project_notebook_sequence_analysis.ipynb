{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sequence Analysis with Python\n",
    "\n",
    "Contact: Veli MÃ¤kinen veli.makinen@helsinki.fi"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following assignments introduce applications of hashing with ```dict()``` primitive of Python. While doing so, a rudimentary introduction to biological sequences is given. \n",
    "This framework is then enhanced with probabilities, leading to routines to generate random sequences under some constraints, including a general concept of *Markov-chains*. All these components illustrate the usage of ```dict()```, but at the same time introduce some other computational routines to efficiently deal with probabilities.   \n",
    "The function ```collections.defaultdict``` can be useful.\n",
    "\n",
    "Below are some \"suggested\" imports. Feel free to use and modify these, or not. Generally it's good practice to keep most or all imports in one place. Typically very close to the start of notebooks."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "# !!!!!!!!! IMPORTANT !!!!!!!!!\n",
    "# In exercises 2, 5 and 19 there are two different options for variable \"filename\".\n",
    "# Use the the one with \"src/\" in the beginning of the word for unit tests and the\n",
    "# one without it for getting the outputs. Other exercises depend on these ones after\n",
    "# might need to rerun the whole page.\n",
    "\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import math\n",
    "from numpy.random import choice"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.831112Z",
     "start_time": "2019-07-08T22:04:22.688031Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The automated TMC tests do not test cell outputs. These are intended to be evaluated in the peer reviews. So it is still be a good idea to make the outputs as clear and informative as possible.\n",
    "\n",
    "To keep TMC tests running as well as possible it is recommended to keep global variable assignments in the notebook to a minimum to avoid potential name clashes and confusion. Additionally you should keep all actual code exection in main guards to keep the test running smoothly. If you run [check_sequence.py](https://raw.githubusercontent.com/saskeli/data-analysis-with-python-summer-2019/master/check_outputs.py) in the `part07-e01_sequence_analysis` folder, the script should finish very quickly and optimally produce no output.\n",
    "\n",
    "If you download data from the internet during execution (codon usage table), the parts where downloading is done should not work if you decide to submit to the tmc server. Local tests should work fine."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## DNA and RNA\n",
    "\n",
    "A DNA molecule consist, in principle, of a chain of smaller molecules. These smaller molecules have some common basic components (bases) that repeat. For our purposes it is sufficient to know that these bases are nucleotides adenine, cytosine, guanine, and thymine with abbreviations ```A```, ```C```, ```G```, and ```T```. Given a *DNA sequence* e.g. ```ACGATGAGGCTCAT```, one can reverse engineer (with negligible loss of information) the corresponding DNA molecule.\n",
    "\n",
    "Parts of a DNA molecule can *transcribe* into an RNA molecule. In this process, thymine gets replaced by uracil (```U```). \n",
    "\n",
    "\n",
    "1. Write a function ```dna_to_rna``` to convert a given DNA sequence $s$ into an RNA sequence. For the sake of exercise, use ```dict()``` to store the symbol to symbol encoding rules. Create a program to test your function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "\n",
    "def dna_to_rna(s):\n",
    "    transform = {\"A\":\"A\", \"C\":\"C\", \"G\":\"G\", \"T\":\"U\"}\n",
    "    return \"\".join(transform[nucleo] for nucleo in s)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_rna(\"AACGTGATTTC\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AACGUGAUUUC\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.841952Z",
     "start_time": "2019-07-08T22:04:22.834721Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I created a dictionary with mappings from the dna-nucleotides to rna-nucleotides. The only nucleotide that needed to be transformed was thymine to uracil (T -> U), all the others stayed the same."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The code run as I expected, transforming \"thymines\" in the input to \"uracils\" in the output.\n",
    "\n",
    "Output:\n",
    "\"AACGUGAUUUC\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Proteins\n",
    "\n",
    "Like DNA and RNA, protein molecule can be interpreted as a chain of smaller molecules, where the bases are now amino acids. RNA molecule may *translate* into a protein molecule, but instead of base by base, three bases of RNA correspond to one base of protein. That is, RNA sequence is read triplet (called codon) at a time. \n",
    "\n",
    "2. Consider the codon to amino acid conversion table in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html. Write a function ```get_dict``` to read the table into a ```dict()```, such that for each RNA sequence of length 3, say $\\texttt{AGU}$, the hash table stores the conversion rule to the corresponding amino acid. You may store the html page to your local src directory,\n",
    "and parse that file."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "def get_dict():\n",
    "    filename = \"codon_data.html\" # use to get the outputs\n",
    "    # filename = \"src/codon_data.html\" # use for local unit tests\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        soup = BeautifulSoup(f)\n",
    "        \n",
    "    # Clean the data\n",
    "    data = str(soup.pre).replace(\"<pre>\", \"\").replace(\"</pre>\", \"\")\n",
    "    \n",
    "    # Find all the triplet-amino acid pairs by using regular expressions\n",
    "    pattern = r\"(\\w{3})\\s([A-Z*])\"\n",
    "    pairs = re.findall(pattern, data)\n",
    "    \n",
    "    # Create the dataframe\n",
    "    cols = [\"triplet\", \"amino acid\"]\n",
    "    df = pd.DataFrame(pairs, columns=cols)\n",
    "    \n",
    "    # Get the columns from the dataframe and squeeze them into series\n",
    "    triplets = df.triplet.squeeze()\n",
    "    amino_acids = df[\"amino acid\"].squeeze()\n",
    "    \n",
    "    # Set triplets as the index for the amino_acids\n",
    "    amino_acids.index = triplets\n",
    "    \n",
    "    # Turn the series into a dictionary\n",
    "    return amino_acids.to_dict()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_aa = get_dict()\n",
    "    print(codon_to_aa)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.867855Z",
     "start_time": "2019-07-08T22:04:22.845885Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I used BeautifulSoup to get the table into string format and then I cleaned the data. I used regular expressions to find all the triplet-amino_acid pairs. After this, I turned these pairs into a dataframe and then to seperate series. I then formed the dictionary by setting triplets as the index for amino_acids and then using the \"to_dict\" method on that series."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Execution went as expected, outputting the dictionary with all the triplet-->amino_acid pairs from the original table.\n",
    "\n",
    "Output:\n",
    "{'UUU': 'F', 'UCU': 'S', 'UAU': 'Y', 'UGU': 'C', 'UUC': 'F', 'UCC': 'S', 'UAC': 'Y', 'UGC': 'C', 'UUA': 'L', 'UCA': 'S', 'UAA': '*', 'UGA': '*', 'UUG': 'L', 'UCG': 'S', 'UAG': '*', 'UGG': 'W', 'CUU': 'L', 'CCU': 'P', 'CAU': 'H', 'CGU': 'R', 'CUC': 'L', 'CCC': 'P', 'CAC': 'H', 'CGC': 'R', 'CUA': 'L', 'CCA': 'P', 'CAA': 'Q', 'CGA': 'R', 'CUG': 'L', 'CCG': 'P', 'CAG': 'Q', 'CGG': 'R', 'AUU': 'I', 'ACU': 'T', 'AAU': 'N', 'AGU': 'S', 'AUC': 'I', 'ACC': 'T', 'AAC': 'N', 'AGC': 'S', 'AUA': 'I', 'ACA': 'T', 'AAA': 'K', 'AGA': 'R', 'AUG': 'M', 'ACG': 'T', 'AAG': 'K', 'AGG': 'R', 'GUU': 'V', 'GCU': 'A', 'GAU': 'D', 'GGU': 'G', 'GUC': 'V', 'GCC': 'A', 'GAC': 'D', 'GGC': 'G', 'GUA': 'V', 'GCA': 'A', 'GAA': 'E', 'GGA': 'G', 'GUG': 'V', 'GCG': 'A', 'GAG': 'E', 'GGG': 'G'}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. Use the same conversion table as above, but now write function `get_dict_list` to read the table into a `dict()`, such that for each amino acid the hash table stores the list of codons encoding it.    "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "\n",
    "def get_dict_list():\n",
    "    # Get the dict from previous exercise\n",
    "    og_dict = get_dict()\n",
    "    \n",
    "    # Unpack to keys and values\n",
    "    keys, values = og_dict.keys(), og_dict.values()\n",
    "    \n",
    "    # Build the new dictionary\n",
    "    new_dict = defaultdict(list)\n",
    "    for k, v in zip(values, keys):\n",
    "        new_dict[k].append(v)\n",
    "        \n",
    "    return dict(new_dict)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    aa_to_codons = get_dict_list()\n",
    "    print(aa_to_codons)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.882386Z",
     "start_time": "2019-07-08T22:04:22.872449Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I called the function \"get_dict\" to get the dictionary from previous exercise. I extracted the keys and values from the dictionary and then zipped them back together in reverse order. After this I build the new dictionary by using defaultdict with lists and appending the values to the lists."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Function worked correctly, mapping every aminoacid to its respective nucleotide triplets.\n",
    "\n",
    "{'F': ['UUU', 'UUC'], 'S': ['UCU', 'UCC', 'UCA', 'UCG', 'AGU', 'AGC'], 'Y': ['UAU', 'UAC'], 'C': ['UGU', 'UGC'], 'L': ['UUA', 'UUG', 'CUU', 'CUC', 'CUA', 'CUG'], '*': ['UAA', 'UGA', 'UAG'], 'W': ['UGG'], 'P': ['CCU', 'CCC', 'CCA', 'CCG'], 'H': ['CAU', 'CAC'], 'R': ['CGU', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'Q': ['CAA', 'CAG'], 'I': ['AUU', 'AUC', 'AUA'], 'T': ['ACU', 'ACC', 'ACA', 'ACG'], 'N': ['AAU', 'AAC'], 'K': ['AAA', 'AAG'], 'M': ['AUG'], 'V': ['GUU', 'GUC', 'GUA', 'GUG'], 'A': ['GCU', 'GCC', 'GCA', 'GCG'], 'D': ['GAU', 'GAC'], 'G': ['GGU', 'GGC', 'GGA', 'GGG'], 'E': ['GAA', 'GAG']}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the conversion tables at hand, the following should be trivial to solve.\n",
    "\n",
    "4. Fill in function ```rna_to_prot``` in the stub solution to convert a given DNA sequence $s$ into a protein sequence. \n",
    "You may use the dictionaries from exercises 2 and 3. You can test your program with `ATGATATCATCGACGATGTAG`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "\n",
    "def rna_to_prot(s):\n",
    "    # Get the dictionary that converts triplets to amino acids\n",
    "    dictionary = get_dict()\n",
    "    \n",
    "    # Transform triplets into amino acids and add them to the protein string\n",
    "    i = 0\n",
    "    end = len(s) - 3\n",
    "    prot = \"\"\n",
    "    while i <= end:\n",
    "        codon = s[i:i+3]\n",
    "        prot += dictionary[codon]\n",
    "        i += 3\n",
    "    \n",
    "    # Turn the list into a string\n",
    "    return prot\n",
    "\n",
    "def dna_to_prot(s):\n",
    "    return rna_to_prot(dna_to_rna(s))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(dna_to_prot(\"ATGATATCATCGACGATGTAG\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MISSTM*\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.913321Z",
     "start_time": "2019-07-08T22:04:22.906646Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I imported the dictionary that turns nucleotide triplets into amino acids. Then I created an empty string and added the transformed amino acids to the string.Â§"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Printed result worked as expected\n",
    "\n",
    "Output: \"MISSTM*\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may notice that there are $4^3=64$ different codons, but only 20 amino acids. That is, some triplets encode the same amino acid.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Reverse translation\n",
    "\n",
    "It has been observed that among the codons coding the same amino acid, some are more frequent than others. These frequencies can be converted to probabilities. E.g. consider codons `AUU`, `AUC`, and `AUA` that code for amino acid isoleucine.\n",
    "If they are observed, say, 36, 47, 17 times, respectively, to code isoleucine in a dataset, the probability that a random such event is `AUU` $\\to$ isoleucine is 36/100.\n",
    "\n",
    "This phenomenon is called *codon adaptation*, and for our purposes it works as a good introduction to generation of random sequences under constraints.   \n",
    "\n",
    "5. Consider the codon adaptation frequencies in http://htmlpreview.github.io/?https://github.com/csmastersUH/data_analysis_with_python_2020/blob/master/Codon%20usage%20table.html and read them into a ```dict()```, such that for each RNA sequence of length 3, say `AGU`, the hash table stores the probability of that codon among codons encoding the same amino acid.\n",
    "Put your solution in the ```get_probabability_dict``` function. Use the column \"([number])\" to estimate the probabilities, as the two preceding columns contain truncated values.  "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "def get_probabability_dict():\n",
    "    filename = \"codon_data.html\" # use to get the outputs\n",
    "    # filename = \"src/codon_data.html\" # use for local unit tests\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        soup = BeautifulSoup(f)\n",
    "        \n",
    "    # Clean the data\n",
    "    data = str(soup.pre).replace(\"<pre>\", \"\").replace(\"</pre>\", \"\")\n",
    "    data = data.replace(\"\\n\", \"  \")\n",
    "    \n",
    "    # Find all the seperate columns by using regular expressions\n",
    "    pattern = r\"(\\w{3})\\s([A-Z*])\\s\\d\\.\\d{2}\\s{1,2}\\d{1,2}\\.\\d\\s\\(\\s?(\\d{5,7})\\)\"\n",
    "    groups = re.findall(pattern, data)\n",
    "    \n",
    "    # Create a dataframe, change the datatype of the number column\n",
    "    cols = [\"codon\", \"amino_acid\", \"number\"]\n",
    "    df = pd.DataFrame(groups, columns=cols)\n",
    "    df[\"number\"] = df[\"number\"].astype(float)\n",
    "    \n",
    "    # Group by the aminoacids\n",
    "    grouped = df.groupby(\"amino_acid\")\n",
    "    \n",
    "    # Loop over the groups and put them in a dictionary according to their precise fractions\n",
    "    probabilities = {}\n",
    "    for _, group in grouped:\n",
    "        codons, nums = group.codon, group.number\n",
    "        total_appearances = group.number.sum()\n",
    "        \n",
    "        for i in range(len(group)):\n",
    "            c, n = codons.iloc[i], nums.iloc[i]\n",
    "            probabilities[c] = n / total_appearances\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return probabilities\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    codon_to_prob = get_probabability_dict()\n",
    "    items = sorted(codon_to_prob.items(), key=lambda x: x[0])\n",
    "    for i in range(1 + len(items)//6):\n",
    "        print(\"\\t\".join(\n",
    "            f\"{k}: {v:.6f}\"\n",
    "            for k, v in items[i*6:6+i*6]\n",
    "        ))\n",
    "    \n",
    "    get_probabability_dict()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
      "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
      "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
      "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
      "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
      "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
      "GCA: 0.228121\tGCC: 0.399781\tGCG: 0.106176\tGCU: 0.265922\tGGA: 0.249922\tGGC: 0.337109\n",
      "GGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\tGUG: 0.463346\tGUU: 0.181770\n",
      "UAA: 0.297019\tUAC: 0.556662\tUAG: 0.236738\tUAU: 0.443338\tUCA: 0.150517\tUCC: 0.217960\n",
      "UCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.543843\tUGG: 1.000000\tUGU: 0.456157\n",
      "UUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:22.966173Z",
     "start_time": "2019-07-08T22:04:22.956013Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I cleaned the data by finding the seperate columns by using regular expressions. Then I created a dataframe and changed the datatype of the \"number\" column. I grouped the dataframe by the amino acids. At the end I created the probability dictionary by first taking the frequency of one codon and the dividing it by the frequency of all the codons corresponding to the same amino acid."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The code passed the unit tests and it returned believable results, close to the approximate values.\n",
    "\n",
    "Output:\n",
    "AAA: 0.434049\tAAC: 0.529633\tAAG: 0.565951\tAAU: 0.470367\tACA: 0.284188\tACC: 0.355232\n",
    "ACG: 0.113812\tACU: 0.246769\tAGA: 0.214658\tAGC: 0.239938\tAGG: 0.211091\tAGU: 0.149602\n",
    "AUA: 0.169062\tAUC: 0.469866\tAUG: 1.000000\tAUU: 0.361072\tCAA: 0.265017\tCAC: 0.581485\n",
    "CAG: 0.734983\tCAU: 0.418515\tCCA: 0.276603\tCCC: 0.323470\tCCG: 0.113196\tCCU: 0.286731\n",
    "CGA: 0.108812\tCGC: 0.183777\tCGG: 0.201554\tCGU: 0.080108\tCUA: 0.071380\tCUC: 0.195577\n",
    "CUG: 0.395702\tCUU: 0.131716\tGAA: 0.422453\tGAC: 0.535458\tGAG: 0.577547\tGAU: 0.464542\n",
    "GCA: 0.228121\tGCC: 0.399781\tGCG: 0.106176\tGCU: 0.265922\tGGA: 0.249922\tGGC: 0.337109\n",
    "GGG: 0.249882\tGGU: 0.163087\tGUA: 0.116577\tGUC: 0.238306\tGUG: 0.463346\tGUU: 0.181770\n",
    "UAA: 0.297019\tUAC: 0.556662\tUAG: 0.236738\tUAU: 0.443338\tUCA: 0.150517\tUCC: 0.217960\n",
    "UCG: 0.054398\tUCU: 0.187586\tUGA: 0.466243\tUGC: 0.543843\tUGG: 1.000000\tUGU: 0.456157\n",
    "UUA: 0.076568\tUUC: 0.535866\tUUG: 0.129058\tUUU: 0.464134"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now you should have everything in place to easily solve the following.\n",
    "\n",
    "\n",
    "6. Write a class ```ProteinToMaxRNA``` with a ```convert``` method which converts a protein sequence into the most likely RNA sequence to be the source of this protein. Run your program with `LTPIQNRA`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "class ProteinToMaxRNA:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s):\n",
    "        # Data structures\n",
    "        rna_sequence = \"\"\n",
    "        aa_to_codons = get_dict_list()\n",
    "        probs = get_probabability_dict()\n",
    "        \n",
    "        # Loop over the protein sequence\n",
    "        for aa in s:\n",
    "            codons = aa_to_codons[aa]\n",
    "            highest_prob = 0\n",
    "            best = \"\"\n",
    "            \n",
    "            # Loop over the corresponding codons\n",
    "            for c in codons:\n",
    "                curr_prob = probs[c]\n",
    "                if curr_prob > highest_prob:\n",
    "                    highest_prob = curr_prob\n",
    "                    best = c\n",
    "            rna_sequence += best\n",
    "            \n",
    "        return rna_sequence\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    protein_to_rna = ProteinToMaxRNA()\n",
    "    print(protein_to_rna.convert(\"LTPIQNRA\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CUGACCCCCAUCCAGAACAGAGCC\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.000743Z",
     "start_time": "2019-07-08T22:04:22.992108Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first created an empty string for the sequence and then imported the dictionaries from previous exercises. I looped over the aminoacids in the given sequence and got the possible codons corresponding to the current amino acid. After this I looped over the codons and checked, which of them had the highest change of occurring. Then I added the codon with the highest probability to the string and returned the complete sequence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Output looks right and completed the tests.\n",
    "\n",
    "Output: \"CUGACCCCCAUCCAGAACAGAGCC\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we are almost ready to produce random RNA sequences that code a given protein sequence. For this, we need a subroutine to *sample from a probability distribution*. Consider our earlier example of probabilities 36/100, 47/100, and 17/100 for `AUU`, `AUC`, and `AUA`, respectively. \n",
    "Let us assume we have a random number generator ```random()``` that returns a random number from interval $[0,1)$. We may then partition the unit interval according to cumulative probabilities to $[0,36/100), [36/100,83/100), [83/100,1)$, respectively. Depending which interval the number ```random()``` hits, we select the codon accordingly.\n",
    "\n",
    "7. Write a function ```random_event``` that chooses a random event, given a probability distribution (set of events whose probabilities sum to 1).\n",
    "You can use function ```random.uniform``` to produce values uniformly at random from the range $[0,1)$. The distribution should be given to your function as a dictionary from events to their probabilities."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "def random_event(dist):\n",
    "    \"\"\"\n",
    "    Takes as input a dictionary from events to their probabilities.\n",
    "    Return a random event sampled according to the given distribution.\n",
    "    The probabilities must sum to 1.0\n",
    "    \"\"\"\n",
    "    \n",
    "    # Random number and cumulative probability\n",
    "    rand = np.random.uniform(0, 1)\n",
    "    cumu = 0\n",
    "    \n",
    "    # Loop over distribution items\n",
    "    for codon, prob in dist.items():\n",
    "        if prob + cumu >= rand:\n",
    "            return codon\n",
    "        else:\n",
    "            cumu += prob\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distribution = dict(zip(\"ACGT\", [0.10, 0.35, 0.15, 0.40]))\n",
    "    print(\", \".join(random_event(distribution) for _ in range(29)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "C, T, C, C, C, T, C, A, T, A, C, C, G, C, C, T, T, T, G, T, T, G, T, G, A, C, T, G, G\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.036655Z",
     "start_time": "2019-07-08T22:04:23.030067Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I created the random number with uniform distribution and cumulative probability variable with zero as default value. I looped over all the codons in the distribution and returned a codon when the cumulative probability was higher than the random number."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The function works without errors and gives random results.\n",
    "\n",
    "Three example outputs:\n",
    "1. C, C, C, G, T, C, T, T, T, C, T, T, G, T, T, T, C, T, G, A, C, T, T, C, T, C, G, A, T\n",
    "2. T, T, A, C, A, T, C, A, T, C, T, T, T, C, T, T, C, T, T, A, T, T, T, C, A, T, C, T, T\n",
    "3. C, T, C, C, C, T, C, A, T, A, C, C, G, C, C, T, T, T, G, T, T, G, T, G, A, C, T, G, G"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With this general routine, the following should be easy to solve.\n",
    " \n",
    "8. Write a class ```ProteinToRandomRNA``` to produce a random RNA sequence encoding the input protein sequence according to the input codon adaptation probabilities. The actual conversion is done through the ```convert``` method. Run your program with `LTPIQNRA`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "class ProteinToRandomRNA(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def convert(self, s):\n",
    "        # Data structures\n",
    "        rna_sequence = \"\"\n",
    "        aa_to_codons = get_dict_list()\n",
    "        prob_dict = get_probabability_dict()\n",
    "        \n",
    "        # Loop over the protein sequence\n",
    "        for aa in s:\n",
    "            # Create the (codon -> probability) distribution\n",
    "            codons = aa_to_codons[aa]\n",
    "            probs = [prob_dict[codon] for codon in codons]\n",
    "            dist = dict(zip(codons, probs))\n",
    "            \n",
    "            # Use the random event method with the created distribution and append to the sequence\n",
    "            rna_sequence += random_event(dist)\n",
    "            \n",
    "        # Return the rna sequence\n",
    "        return rna_sequence\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    protein_to_random_codons = ProteinToRandomRNA()\n",
    "    print(protein_to_random_codons.convert(\"LTPIQNRA\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "UUGACUCCCAUCCAAAAUAGAGCC\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.073660Z",
     "start_time": "2019-07-08T22:04:23.067966Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first created an empty string for rna-sequence and imported two dictionaries from previous exercises. Then I looped over the amino acids in the given sequence and created a distribution with codon triplets linked to their respective probabilities. Then I used the randomEvent-method to get a random codon and added it to the rna_sequence created in the beginning."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The function works as expected: the outputs are the correct length and random.\n",
    "\n",
    "Three example outputs:\n",
    "1. CUGACUCCUAUACAGAAUCGGGCU\n",
    "2. CUCACCCCCAUCCAGAAUCGGGCG\n",
    "3. UUGACUCCCAUCCAAAAUAGAGCC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generating DNA sequences with higher-order Markov chains\n",
    "\n",
    "We will now reuse the machinery derived above in a related context. We go back to DNA sequences, and consider some easy statistics that can be used to characterize the sequences. \n",
    "First, just the frequencies of bases $\\texttt{A}$, $\\texttt{C}$, $\\texttt{G}$, $\\texttt{T}$ may reveal the species from which the input DNA originates; each species has a different base composition that has been formed during evolution. \n",
    "More interestingly, the areas where DNA to RNA transcription takes place (coding region) have an excess of $\\texttt{C}$ and $\\texttt{G}$ over $\\texttt{A}$ and $\\texttt{T}$. To detect such areas a common routine is to just use a *sliding window* of fixed size, say $k$, and compute for each window position \n",
    "$T[i..i+k-1]$ the base frequencies, where $T[1..n]$ is the input DNA sequence. When sliding the window from  $T[i..i+k-1]$ to $T[i+1..i+k]$ frequency $f(T[i])$ gets decreases by one and $f(T[i+k])$ gets increased by one. \n",
    "\n",
    "9. Write a *generator* ```sliding_window``` to compute sliding window base frequencies so that each moving of the window takes constant time. We saw in the beginning of the course one way how to create generators using\n",
    "  generator expression. Here we use a different way. For the function ```sliding_window``` to be a generator, it must have at least   one ```yield``` expression, see [https://docs.python.org/3/reference/expressions.html#yieldexpr](https://docs.python.org/3/reference/expressions.html#yieldexpr).\n",
    "  \n",
    "  Here is an example of a generator expression that works similarily to the built in `range` generator:\n",
    "  ```Python\n",
    "  def range(a, b=None, c=1):\n",
    "      current = 0 if b == None else a\n",
    "      end = a if b == None else b\n",
    "      while current < end:\n",
    "          yield current\n",
    "          current += c\n",
    "  ```\n",
    "  A yield expression can be used to return a value and *temporarily* return from the function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "def sliding_window(s, k):\n",
    "    \"\"\"\n",
    "    This function returns a generator that can be iterated over all\n",
    "    starting position of a k-window in the sequence.\n",
    "    For each starting position the generator returns the nucleotide frequencies\n",
    "    in the window as a dictionary.\n",
    "    \"\"\"\n",
    "    # Helper function to initialize current frequencies\n",
    "    def init_freqs():\n",
    "        return {\"A\": 0, \"C\": 0, \"G\": 0, \"T\": 0}\n",
    "    \n",
    "    # Create the window and frequencies\n",
    "    window = s[:k]\n",
    "    freqs = init_freqs()\n",
    "    \n",
    "    # Index variables\n",
    "    end = len(s) - k\n",
    "    i = 0\n",
    "    \n",
    "    # Loop as long as there are k-length windows left\n",
    "    while i <= end:\n",
    "        # Update frequencies\n",
    "        j = 0\n",
    "        while j < k:\n",
    "            nucleo = window[j]\n",
    "            freqs[nucleo] += 1\n",
    "            j += 1\n",
    "        \n",
    "        # Yield the current window frequencies\n",
    "        yield freqs\n",
    "        \n",
    "        # Reset freqs, slide the window one step\n",
    "        if i < end:\n",
    "            freqs = init_freqs()\n",
    "            window = window[1:] + s[i+k]\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    s = \"TCCCGACGGCCTTGCC\"\n",
    "    for d in sliding_window(s, 4):\n",
    "        print(d)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
      "{'A': 0, 'C': 3, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
      "{'A': 0, 'C': 2, 'G': 0, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
      "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.111365Z",
     "start_time": "2019-07-08T22:04:23.100858Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first created a helper function to initialize the dictionary for nucleotide frequencies. Then I initialized the first window, frequencies and index variables. I looped over the sequence, first updating the frequencies, then yielding the result dictionary and then resetting the window and frequencies for the next loop."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The function outputs correct results: 13 different dictionaries with the right frequencies.\n",
    "\n",
    "Output:\n",
    "{'A': 0, 'C': 3, 'G': 0, 'T': 1}\n",
    "{'A': 0, 'C': 3, 'G': 1, 'T': 0}\n",
    "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
    "{'A': 1, 'C': 2, 'G': 1, 'T': 0}\n",
    "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
    "{'A': 1, 'C': 1, 'G': 2, 'T': 0}\n",
    "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
    "{'A': 0, 'C': 2, 'G': 2, 'T': 0}\n",
    "{'A': 0, 'C': 2, 'G': 1, 'T': 1}\n",
    "{'A': 0, 'C': 2, 'G': 0, 'T': 2}\n",
    "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
    "{'A': 0, 'C': 1, 'G': 1, 'T': 2}\n",
    "{'A': 0, 'C': 2, 'G': 1, 'T': 1}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " \n",
    "Our models so far have been so-called *zero-order* models, as each event has been independent of other events. With sequences, the dependencies of events are naturally encoded by their *contexts*. Considering that a sequence is produced from left-to-right, a *first-order* context for $T[i]$ is $T[i-1]$, that is, the immediately preceding symbol. *First-order Markov chain* is a sequence produced by generating $c=T[i]$ with the probability of event of seeing symbol $c$ after previously generated symbol $a=T[i-1]$. The first symbol of the chain is sampled according to the zero-order model.  \n",
    "The first-order model can naturally be extended to contexts of length $k$, with $T[i]$ depending on $T[i-k..i-1]$. Then the first $k$ symbols of the chain are sampled according to the zero-order model.  The following assignments develop the routines to work with the *higher-order Markov chains*. \n",
    "In what follows, a $k$-mer is a substring $T[i..i+k-1]$ of the sequence at an arbitrary position. \n",
    "\n",
    "10. Write function ```context_list``` that given an input DNA sequence $T$ associates to each $k$-mer $W$ the concatenation of all symbols $c$ that appear after context $W$ in $T$, that is, $T[i..i+k]=Wc$. For example, <span style=\"color:red; font:courier;\">GA</span> is associated to <span style=\"color:blue; font: courier;\">TCT</span> in $T$=<span style=\"font: courier;\">AT<span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>ATCATC<span style=\"color:red;\">GA</span><span style=\"color:blue;\">C</span><span style=\"color:red;\">GA</span><span style=\"color:blue;\">T</span>GTAG</span>, when $k=2$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "def context_list(s, k):\n",
    "    # Create the window and frequencies\n",
    "    window = s[:k]\n",
    "    patterns = defaultdict(str)\n",
    "    \n",
    "    # Index variables\n",
    "    end = len(s) - k\n",
    "    i = 0\n",
    "    \n",
    "    # Loop as long as there are k-length windows left\n",
    "    while i < end:\n",
    "        following = s[i+k]\n",
    "        patterns[window] += following\n",
    "        \n",
    "        # Update the window and the counter\n",
    "        window = window[1:] + following\n",
    "        i += 1\n",
    "        \n",
    "    return dict(patterns)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATCTAG\"\n",
    "    d = context_list(s, k)\n",
    "    print(d)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.168108Z",
     "start_time": "2019-07-08T22:04:23.162648Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I initialized the window, the pattern dictionary and the index variables. I looped while there were k-length patterns with a single nucleotide after them. I built the dictionary and returned the patterns in the end."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Function outputs a dictionary with right contexts.\n",
    "\n",
    "Output:\n",
    "{'AT': 'GACCC', 'TG': 'A', 'GA': 'TCT', 'TA': 'TG', 'TC': 'AGT', 'CA': 'T', 'CG': 'AA', 'AC': 'G', 'CT': 'A'}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "11. With the above solution, write function ```context_probabilities``` to count the frequencies of symbols in each context and convert these frequencies into probabilities. Run `context_probabilities` with $T=$ `ATGATATCATCGACGATGTAG` and $k$ values 0 and 2."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "def context_probabilities(s, k):\n",
    "    # Get the context list and initialize probability dictionary\n",
    "    context = context_list(s, k)\n",
    "    probs = {}\n",
    "    \n",
    "    # Build a dictionary inside a dictionary\n",
    "    # => pattern --> {nucleotide --> probability}\n",
    "    for pattern, nucleotides in context.items():\n",
    "        for nucleo in nucleotides:\n",
    "            portion = 1 / len(nucleotides)\n",
    "            if probs.get(pattern) == None:\n",
    "                probs[pattern] = {nucleo: portion}\n",
    "            elif probs[pattern].get(nucleo) == None:\n",
    "                probs[pattern][nucleo] = portion\n",
    "            else:\n",
    "                probs[pattern][nucleo] += portion\n",
    "                \n",
    "    return probs\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    T = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(context_probabilities(T, 0))\n",
    "    print(context_probabilities(T, 2))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'': {'A': 1.0}, 'A': {'T': 0.7142857142857142, 'C': 0.14285714285714285, 'G': 0.14285714285714285}, 'T': {'G': 0.3333333333333333, 'A': 0.3333333333333333, 'C': 0.3333333333333333}, 'G': {'A': 0.75, 'T': 0.25}, 'C': {'A': 0.3333333333333333, 'G': 0.6666666666666666}}\n",
      "{'AT': {'G': 0.4, 'A': 0.2, 'C': 0.4}, 'TG': {'A': 0.5, 'T': 0.5}, 'GA': {'T': 0.6666666666666666, 'C': 0.3333333333333333}, 'TA': {'T': 0.5, 'G': 0.5}, 'TC': {'A': 0.5, 'G': 0.5}, 'CA': {'T': 1.0}, 'CG': {'A': 1.0}, 'AC': {'G': 1.0}, 'GT': {'A': 1.0}}\n",
      "{}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.218964Z",
     "start_time": "2019-07-08T22:04:23.213773Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first imported the context list from the previous exercise and initialized the probability dictionary. Then I looped over all the key-value pairs in context list and the created a nested loop by looping over the nucleotides. I built the dictionary with the help of if-else by checking if there was an entry with the specific nucleotide and then acting accordingly etc."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Outputs are correct for both k. For some reason one test fails with message: TestContextProbabilities: test_empty_context\n",
    "unsupported operand type(s) for -: 'dict' and 'dict'. \n",
    "\n",
    "Outputs:\n",
    "1. k = 0: {'': {'A': 1.0}, 'A': {'T': 0.7142857142857142, 'C': 0.14285714285714285, 'G': 0.14285714285714285}, 'T': {'G': 0.3333333333333333, 'A': 0.3333333333333333, 'C': 0.3333333333333333}, 'G': {'A': 0.75, 'T': 0.25}, 'C': {'A': 0.3333333333333333, 'G': 0.6666666666666666}}\n",
    "2. k = 2: {'AT': {'G': 0.4, 'A': 0.2, 'C': 0.4}, 'TG': {'A': 0.5, 'T': 0.5}, 'GA': {'T': 0.6666666666666666, 'C': 0.3333333333333333}, 'TA': {'T': 0.5, 'G': 0.5}, 'TC': {'A': 0.5, 'G': 0.5}, 'CA': {'T': 1.0}, 'CG': {'A': 1.0}, 'AC': {'G': 1.0}, 'GT': {'A': 1.0}}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "12. With the above solution and the function ```random_event``` from the earlier exercise, write class ```MarkovChain```. Its ```generate``` method should generate a random DNA sequence following the original $k$-th order Markov chain probabilities. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "class MarkovChain:\n",
    "    def __init__(self, zeroth, kth, k=2):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def generate(self, n, seed=None):\n",
    "        # Set the pseudorandom state\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        # Generate the first k entries\n",
    "        markov = \"\"\n",
    "        first_state = min(self.k, n)\n",
    "        for _ in range(first_state): \n",
    "            markov += random_event(self.zeroth)\n",
    "            \n",
    "        # Initialize the sliding window and the distribution\n",
    "        window = markov\n",
    "        dist = {}\n",
    "            \n",
    "        # Generate the rest of the entries\n",
    "        for i in range(n - self.k): \n",
    "            if self.kth.get(window) == None: \n",
    "                dist = self.zeroth\n",
    "            else:\n",
    "                dist = self.kth[window]\n",
    "            markov += random_event(dist)\n",
    "            \n",
    "            window = markov[i+1:]\n",
    "        \n",
    "        return markov\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    zeroth = {'A': 0.2, 'C': 0.19, 'T': 0.31, 'G': 0.3}\n",
    "    kth = {'GT': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0},\n",
    "           'CA': {'A': 0.0, 'C': 0.0, 'T': 1.0, 'G': 0.0},\n",
    "           'TC': {'A': 0.5, 'C': 0.0, 'T': 0.0, 'G': 0.5},\n",
    "           'GA': {'A': 0.0, 'C': 0.3333333333333333, 'T': 0.6666666666666666, 'G': 0.0},\n",
    "           'TG': {'A': 0.5, 'C': 0.0, 'T': 0.5, 'G': 0.0},\n",
    "           'AT': {'A': 0.2, 'C': 0.4, 'T': 0.0, 'G': 0.4},\n",
    "           'TA': {'A': 0.0, 'C': 0.0, 'T': 0.5, 'G': 0.5},\n",
    "           'AC': {'A': 0.0, 'C': 0.0, 'T': 0.0, 'G': 1.0},\n",
    "           'CG': {'A': 1.0, 'C': 0.0, 'T': 0.0, 'G': 0.0}}\n",
    "    n = 10    \n",
    "    seed = 0\n",
    "    mc = MarkovChain(zeroth, kth)\n",
    "    print(mc.generate(n, seed))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TGTATGATGA\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.279315Z",
     "start_time": "2019-07-08T22:04:23.253983Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I set the seed for the state. Then I created the first k-entries for the markov chain using zeroth context probabilities. I used the the sliding window technique to generate the rest of the sequence using kth context probabilities. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Output works as expected with the given zeroth and kth context probabilities. It's deterministic and correct length.\n",
    "\n",
    "Output: \"TGTATGATGA\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you have survived so far without problems, please run your program a few more times with different inputs. At some point you should get a lookup error in your hash-table! The reason for this is not your code, but the way we defined the model: Some $k$-mers may not be among the training data (input sequence $T$), but such can be generated as the first $k$-mer that is generated using the zero-order model.  \n",
    "\n",
    "A general approach to fixing such issues with incomplete training data is to use *pseudo counts*. That is, all imaginable events are initialized to frequency count 1.   \n",
    "\n",
    "13. Write a new solution `context_pseudo_probabilities` based on the solution to problem 11. But this time use pseudo counts in order to obtain a $k$-th order Markov chain that can assign a probability for any DNA sequence. You may use the standard library function `itertools.product` to iterate over all $k$-mer of given length (`product(\"ACGT\", repeat=k)`)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "def context_pseudo_probabilities(s, k):\n",
    "    # Helper function to initialize the probability dictionary\n",
    "    def init_dict():\n",
    "        return {\"A\": 1, \"C\": 1, \"G\": 1, \"T\": 1}\n",
    "    \n",
    "    if k != 0:\n",
    "        # Aminoacid pairs\n",
    "        pairs = product(\"ACGT\", repeat=k)\n",
    "        \n",
    "        # Initialize the probability dictionary\n",
    "        probs = {}\n",
    "        for pair in pairs:\n",
    "            pattern = \"\".join(pair)\n",
    "            probs[pattern] = init_dict()    \n",
    "        \n",
    "        # Get the context list\n",
    "        context = context_list(s, k)\n",
    "        \n",
    "        # Build a dictionary inside a dictionary\n",
    "        # => pattern --> {nucleotide --> frequency}\n",
    "        for pattern, nucleotides in context.items():\n",
    "            for nucleo in nucleotides:\n",
    "                probs[pattern][nucleo] += 1\n",
    "    else:\n",
    "        probs = {\"\": init_dict()}\n",
    "        # Build a dictionary inside a dictionary\n",
    "        # => pattern --> {nucleotide --> frequency}\n",
    "        for letter in s:\n",
    "            probs[\"\"][letter] += 1\n",
    "            \n",
    "    # Turn frequencies into pseudo probabilities\n",
    "    for pattern, freqs in probs.items():\n",
    "        divider = sum(freqs.values())\n",
    "        for k, v in freqs.items():\n",
    "            probs[pattern][k] = v / divider\n",
    "                \n",
    "    return probs\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = context_pseudo_probabilities(s, k)\n",
    "    zeroth = context_pseudo_probabilities(s, 0)[\"\"]\n",
    "    print(f\"zeroth: {zeroth}\")\n",
    "    print(\"\\n\".join(f\"{k}: {dict(v)}\" for k, v in kth.items()))\n",
    "    \n",
    "    print(\"\\n\", MarkovChain(zeroth, kth, k).generate(20))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "zeroth: {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "\n",
      " AGCTGCGAGTCATATCACGA\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.303566Z",
     "start_time": "2019-07-08T22:04:23.296028Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I made a helper function for initializing dictionaries. Then I created {pattern --> {nucleotide --> frequency}} dictionaries for zeroth and kth contexts. Finally I turned those frequencies into probabilities for each nucleotide and returned the dictionary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Zeroth and kth context probabilities output correctly.\n",
    "\n",
    "Output:zeroth: {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n",
    "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
    "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
    "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
    "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
    "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
    "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
    "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
    "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
    "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
    "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "\n",
    " AGCTGCGAGTCATATCACGA"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "14. Write class ```MarkovProb``` that given the $k$-th order Markov chain developed above to the constructor, its method ```probability``` computes the probability of a given input DNA sequence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "class MarkovProb:\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def probability(self, s):\n",
    "        # Initialize the window, length of sequence s and the probability calculator\n",
    "        window = \"\"\n",
    "        n = len(s)\n",
    "        prob = 1\n",
    "        \n",
    "        # Update the probability calculator for the first min(k, n) entries \n",
    "        i = 0\n",
    "        first_state = min(self.k, n)\n",
    "        while i < first_state:\n",
    "            nucleo = s[i]\n",
    "            prob *= self.zeroth[nucleo]\n",
    "            window += nucleo\n",
    "            i += 1\n",
    "        \n",
    "        # Update the probability calculator for last n-k entries \n",
    "        while i < n:\n",
    "            nucleo = s[i]\n",
    "            prob *= self.kth[window][nucleo]\n",
    "            window = window[1:] + nucleo\n",
    "            i += 1\n",
    "        \n",
    "        return prob\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    kth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", k)\n",
    "    zeroth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", 0)[\"\"]\n",
    "    mc = MarkovProb(2, zeroth, kth)\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Probability of sequence {s} is {mc.probability(s)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Probability of sequence ATGATATCATCGACGATGTAG is 2.831270190340017e-10\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.346222Z",
     "start_time": "2019-07-08T22:04:23.330779Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I initialized the window, length of sequence s and the probability calculator. Then I calculated and updated probability calculator for the first k entries and then for the last n-k entries. And finally returned the probability for the sequence."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Output probability should be very small given the length of s and it is the case.\n",
    "\n",
    "Output: \"Probability of sequence ATGATATCATCGACGATGTAG is 2.831270190340017e-10\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "With the last assignment you might end up in trouble with precision, as multiplying many small probabilities gives a really small number in the end. There is an easy fix by using so-called log-transform. \n",
    "Consider computation of $P=s_1 s_2 \\cdots s_n$, where $0\\leq s_i\\leq 1$ for each $i$. Taking logarithm in base 2 from both sides gives $\\log _2 P= \\log _2 (s_1 s_2 \\cdots s_n)=\\log_2 s_1 + \\log_2 s_2 + \\cdots \\log s_n= \\sum_{i=1}^n \\log s_i$, with repeated application of the property that the logarithm of a multiplication of two numbers is the sum of logarithms of the two numbers taken separately. The results is abbreviated as log-probability.\n",
    "\n",
    "15. Write class ```MarkovLog``` that given the $k$-th order Markov chain developed above to the constructor, its method ```log_probability``` computes the log-probability of a given input DNA sequence. Run your program with $T=$ `ATGATATCATCGACGATGTAG` and $k=2$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "class MarkovLog(object):\n",
    "\n",
    "    def __init__(self, k, zeroth, kth):\n",
    "        self.k = k\n",
    "        self.zeroth = zeroth\n",
    "        self.kth = kth\n",
    "        \n",
    "    def log_probability(self, s):\n",
    "        # Initialize MarkovProb class and calculate the normal probability\n",
    "        mark = MarkovProb(self.k, self.zeroth, self.kth)\n",
    "        prob = mark.probability(s)\n",
    "        \n",
    "        # Compute the base 2 log probability and return the answer\n",
    "        return math.log(prob, 2)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    kth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", k)\n",
    "    zeroth = context_pseudo_probabilities(\"ATGATATCATCGACGATGTAG\", 0)[\"\"]\n",
    "    mc = MarkovLog(2, zeroth, kth)\n",
    "    s=\"ATGATATCATCGACGATGTAG\"\n",
    "    print(f\"Log probability of sequence {s} is {mc.log_probability(s)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Log probability of sequence ATGATATCATCGACGATGTAG is -31.717831515538307\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.390453Z",
     "start_time": "2019-07-08T22:04:23.379760Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "Solution is very straigth-forward. I used the MarkovProb class from previous exercise to calculate the normal probability. Then I computed the base 2 logarithm with math.log and returned the answer."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Output: \"Log probability of sequence ATGATATCATCGACGATGTAG is -31.717831515538307\"\n",
    "\n",
    "2**(-31.717831515538307) gives the answer to previous task ==> 2.831270190340017e-10\n",
    "so the function works correctly"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, if you try to use the code so far for very large inputs, you might observe that the concatenation of symbols following a context occupy considerable amount of space. This is unnecessary, as we only need the frequencies. \n",
    "\n",
    "16. Optimize the space requirement of your code from exercise 13 for the $k$-th order Markov chain by replacing the concatenations by direct computations of the frequencies. Implement this as the\n",
    "  ```better_context_probabilities``` function."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "def better_context_probabilities(s, k):\n",
    "    # Helper function to initialize the probability dictionary\n",
    "    def init_dict():\n",
    "        return {\"A\": 1, \"C\": 1, \"G\": 1, \"T\": 1}\n",
    "    \n",
    "    probs = {}\n",
    "    \n",
    "    # Create {pattern --> {nucleotide --> frequency}} dictionaries\n",
    "    if k == 0:\n",
    "        probs[\"\"]  = init_dict()\n",
    "        for nucleo in s:\n",
    "            probs[\"\"][nucleo] += 1\n",
    "    else:\n",
    "        # Aminoacid pairs\n",
    "        pairs = product(\"ACGT\", repeat=k)\n",
    "        \n",
    "        for pair in pairs:\n",
    "            pattern = \"\".join(pair)\n",
    "            probs[pattern] = init_dict()\n",
    "        \n",
    "        end = len(s) - k\n",
    "        i = 0\n",
    "        window = s[:k]\n",
    "        \n",
    "        # Count the frequencies for the nucleotides following the pattern\n",
    "        while i < end:\n",
    "            following = s[i+k]\n",
    "            probs[window][following] += 1\n",
    "            window = window[1:] + following\n",
    "            i += 1\n",
    "        \n",
    "    # Turn the frequencies into probabilities\n",
    "    for pattern, freqs in probs.items():\n",
    "        total_freq = sum(freqs.values())\n",
    "        for nucleo, freq in freqs.items():\n",
    "            probs[pattern][nucleo] = freq / total_freq\n",
    "        \n",
    "    return probs\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    kth = better_context_probabilities(s, k)\n",
    "    zeroth = better_context_probabilities(s, 0)\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in kth.items()))\n",
    "    print(\"\\n\".join(f\"{k}: {v}\" for k, v in zeroth.items()))\n",
    "    "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
      "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
      "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
      "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
      "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
      "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
      "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
      "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
      "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
      "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
      ": {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.422302Z",
     "start_time": "2019-07-08T22:04:23.416330Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "The first part of the solution is different for k == 0 and k != 0. When k == 0, I create the dictionary for the empty string. When k != 0, I use the itertools.product to create all the possible k-length patterns and then I initialize the dictionaries. Then I calculate the frequencies for the nucleotides.\n",
    "\n",
    "The second part of the solution is the same for all k. I just turn the frequencies into probabilities based on the total frequency."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Output is the same as in exercise 13.\n",
    "\n",
    "Output: AA: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "AC: {'A': 0.2, 'C': 0.2, 'G': 0.4, 'T': 0.2}\n",
    "AG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "AT: {'A': 0.2222222222222222, 'C': 0.3333333333333333, 'G': 0.3333333333333333, 'T': 0.1111111111111111}\n",
    "CA: {'A': 0.2, 'C': 0.2, 'G': 0.2, 'T': 0.4}\n",
    "CC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "CG: {'A': 0.5, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.16666666666666666}\n",
    "CT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GA: {'A': 0.14285714285714285, 'C': 0.2857142857142857, 'G': 0.14285714285714285, 'T': 0.42857142857142855}\n",
    "GC: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GG: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    "GT: {'A': 0.4, 'C': 0.2, 'G': 0.2, 'T': 0.2}\n",
    "TA: {'A': 0.16666666666666666, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.3333333333333333}\n",
    "TC: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.3333333333333333, 'T': 0.16666666666666666}\n",
    "TG: {'A': 0.3333333333333333, 'C': 0.16666666666666666, 'G': 0.16666666666666666, 'T': 0.3333333333333333}\n",
    "TT: {'A': 0.25, 'C': 0.25, 'G': 0.25, 'T': 0.25}\n",
    ": {'A': 0.32, 'C': 0.16, 'G': 0.24, 'T': 0.28}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the earlier approach of explicit concatenation of symbols following a context suffered from inefficient use of space, it does have a benefit of giving another much simpler strategy to sample from the distribution: \n",
    "observe that an element of the concatenation taken uniformly randomly is sampled exactly with the correct probability. \n",
    "\n",
    "17. Revisit the solution 12 and modify it to directly sample from the concatenation of symbols following a context. The function ```np.random.choice``` may be convenient here. Implement the modified version as the new `SimpleMarkovChain` class."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "source": [
    "class SimpleMarkovChain(object):\n",
    "    def __init__(self, s, k):\n",
    "        self.s = s\n",
    "        self.k = k\n",
    "\n",
    "    def generate(self, n, seed=None):\n",
    "        # Set the pseudorandom state\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Context probabilities\n",
    "        zeroth = better_context_probabilities(self.s, 0)[\"\"]\n",
    "        kth = better_context_probabilities(self.s, self.k) \n",
    "        \n",
    "        # Get the first min(n, k) nucleotides\n",
    "        amount = min(n, self.k)\n",
    "        choices = list(zeroth.keys())\n",
    "        probs = list(zeroth.values())\n",
    "        markov = \"\".join(choice(choices, amount, p=probs))\n",
    "        \n",
    "        # Get the last n-k nucleotides\n",
    "        pattern = markov\n",
    "        i = self.k\n",
    "        while i < n:\n",
    "            curr_dict = kth[pattern]\n",
    "            choices = list(curr_dict.keys())\n",
    "            probs = list(curr_dict.values())\n",
    "            \n",
    "            # Add new random nucleotide to the chain\n",
    "            new_nucl = \"\".join(choice(choices, 1, p=probs))\n",
    "            markov += new_nucl\n",
    "        \n",
    "            # Update pattern and i\n",
    "            pattern = pattern[1:] + new_nucl\n",
    "            i += 1\n",
    "        \n",
    "        return markov\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    k = 2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    n = 10\n",
    "    seed = 7\n",
    "    mc = SimpleMarkovChain(s, k)\n",
    "    print(mc.generate(n, seed))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ATCGTCGACG\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.462556Z",
     "start_time": "2019-07-08T22:04:23.453101Z"
    },
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "I first imported the context probabilities for the kth and zeroth term. Then I took the first min(n,k) nucleotides for the MarkovChain. Then I used the window technique to get the last n-k nucleotides for the chain. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "One of the unit tests doesn't pass but the output is deterministic and of correct length. \n",
    "\n",
    "Output: \"ATCGTCGACG\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## $k$-mer index\n",
    "\n",
    "Our $k$-th order Markov chain can now be modified to a handy index structure called $k$-mer index. This index structure associates to each $k$-mer its list of occurrence positions in DNA sequence $T$.  Given a query $k$-mer $W$, one can thus easily list all positions $i$ with  $T[i..k-1]=W$.\n",
    "\n",
    "18. Implement function ```kmer_index``` inspired by your earlier code for the $k$-th order Markov chain. Test your program with `ATGATATCATCGACGATGTAG` and $k=2$."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "def kmer_index(s, k):\n",
    "    # Initialize the window and the dictionary\n",
    "    window = s[:k]\n",
    "    indices = defaultdict(list)\n",
    "    \n",
    "    # Loop over the chain and add the index to the list\n",
    "    i = 0\n",
    "    end = len(s) - k\n",
    "    while i <= end:\n",
    "        indices[window].append(i)\n",
    "        if i < end:\n",
    "            window = window[1:] + s[i+k]\n",
    "        i += 1\n",
    "        \n",
    "    return indices\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    k=2\n",
    "    s = \"ATGATATCATCGACGATGTAG\"\n",
    "    print(\"Using string:\")\n",
    "    print(s)\n",
    "    print(\"\".join([str(i%10) for i in range(len(s))]))\n",
    "    print(f\"\\n{k}-mer index is:\")\n",
    "    d=kmer_index(s, k)\n",
    "    print(dict(d))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using string:\n",
      "ATGATATCATCGACGATGTAG\n",
      "012345678901234567890\n",
      "\n",
      "2-mer index is:\n",
      "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], 'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.504405Z",
     "start_time": "2019-07-08T22:04:23.494537Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "First I initialized the window and the defaultdict. Then I looped over the sequence and added the starting indices of the k-length subsequences to the dictionary."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "The function outputs a dict with right lists\n",
    "\n",
    "Output: \n",
    "\n",
    "Using string:\n",
    "ATGATATCATCGACGATGTAG\n",
    "012345678901234567890\n",
    "\n",
    "2-mer index is:\n",
    "{'AT': [0, 3, 5, 8, 15], 'TG': [1, 16], 'GA': [2, 11, 14], 'TA': [4, 18], 'TC': [6, 9], 'CA': [7], 'CG': [10, 13], 'AC': [12], 'GT': [17], 'AG': [19]}"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison of probability distributions\n",
    "\n",
    "Now that we know how to learn probability distributions from data, we might want to compare two such distributions, for example, to test if our programs work as intended. \n",
    "\n",
    "Let $P=\\{p_1,p_2,\\ldots, p_n\\}$ and $Q=\\{q_1,q_2,\\ldots, q_n\\}$ be two probability distributions for the same set of $n$ events. This means $\\sum_{i=1}^n p_i=\\sum_{i=1}^n q_i=1$, $0\\leq p_j \\leq 1$, and $0\\leq q_j \\leq 1$ for each event $j$. \n",
    "\n",
    "*Kullback-Leibler divergence* is a measure $d()$ for the *relative entropy* of $P$ with respect to $Q$ defined as \n",
    "$d(P||Q)=\\sum_{i=1}^n p_i \\log\\frac{p_i}{q_i}$.\n",
    "\n",
    "\n",
    "This measure is always non-negative, and 0 only when $P=Q$. It can be interpreted as the gain of knowing $Q$ to encode $P$. Note that this measure is not symmetric.\n",
    "\n",
    "19. Write function ```kullback_leibler``` to compute $d(P||Q)$. Test your solution by generating a random RNA sequence\n",
    "  encoding the input protein sequence according to the input codon adaptation probabilities.\n",
    "  Then you should learn the codon adaptation probabilities from the RNA sequence you generated.\n",
    "  Then try the same with uniformly random RNA sequences (which don't have to encode any\n",
    "  specific protein sequence). Compute the relative entropies between the\n",
    "  three distribution (original, predicted, uniform) and you should observe a clear difference.\n",
    "  Because $d(P||Q)$ is not symmetric, you can either print both $d(P||Q)$ and $d(Q||P)$,\n",
    "  or their average.\n",
    "  \n",
    "  This problem may be fairly tricky. Only the `kullback_leibler` function is automatically tested. The codon probabilities is probably a useful helper function. The main guarded section can be completed by filling out the `pass` sections using tooling from previous parts and fixing the *placeholder* lines."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "source": [
    "def original_probs():\n",
    "    filename = \"codon_data.html\" # use to get the outputs\n",
    "    # filename = \"src/codon_data.html\" # use for local unit tests\n",
    "    \n",
    "    with open(filename) as f:\n",
    "        soup = BeautifulSoup(f)\n",
    "        \n",
    "    # Clean the data\n",
    "    data = str(soup.pre).replace(\"<pre>\", \"\").replace(\"</pre>\", \"\")\n",
    "    data = data.replace(\"\\n\", \"  \")\n",
    "    \n",
    "    # Find all the seperate columns by using regular expressions\n",
    "    pattern = r\"(\\w{3})\\s[A-Z*]\\s\\d\\.\\d{2}\\s{1,2}\\d{1,2}\\.\\d\\s\\(\\s?(\\d{5,7})\\)\"\n",
    "    groups = re.findall(pattern, data)\n",
    "    \n",
    "    # Create a dataframe, change the datatype of the number column\n",
    "    cols = [\"codon\", \"number\"]\n",
    "    df = pd.DataFrame(groups, columns=cols)\n",
    "    df[\"number\"] = df[\"number\"].astype(float)\n",
    "    \n",
    "    # Loop over the groups and put them to a dictionary according to their precise fractions\n",
    "    probabilities = {}\n",
    "    total_appearances = df.number.sum()\n",
    "    for _, row in df.iterrows():\n",
    "        probabilities[row.codon] = row.number / total_appearances\n",
    "    \n",
    "    # Return the dictionary\n",
    "    return probabilities\n",
    "\n",
    "def codon_probabilities(rna):\n",
    "    \"\"\"\n",
    "    Given an RNA sequence, simply calculates the probability of\n",
    "    all 3-mers empirically based on the sequence\n",
    "    \"\"\"\n",
    "    # Initialize all the potential 3-mer permutations\n",
    "    k = 3\n",
    "    perms = product(set(rna), repeat=k)\n",
    "    probs = {}\n",
    "    for codon in perms:\n",
    "        probs[\"\".join(codon)] = 0\n",
    "        \n",
    "    # Use the sliding window method to get the probabilities\n",
    "    end = len(rna) - k\n",
    "    portion = 1 / (end+1)\n",
    "    pattern = rna[:k]\n",
    "    i = 0\n",
    "    while i <= end:\n",
    "        probs[pattern] += portion\n",
    "        if i < end:\n",
    "            pattern = pattern[1:] + rna[i+k]\n",
    "        i += 1\n",
    "        \n",
    "    return probs\n",
    "\n",
    "\n",
    "def kullback_leibler(p, q):\n",
    "    \"\"\"\n",
    "    Computes Kullback-Leibler divergence between two distributions.\n",
    "    Both p and q must be dictionaries from events to probabilities.\n",
    "    The divergence is defined only when q[event] == 0 implies p[event] == 0.\n",
    "    \"\"\"\n",
    "    divergence = 0\n",
    "    for p_prob, q_prob in zip(sorted(p.items()), sorted(q.items())):\n",
    "        try:\n",
    "            if p_prob[1] != 0:\n",
    "                divergence += p_prob[1] * math.log(p_prob[1] / q_prob[1], 2)\n",
    "        except ZeroDivisionError:\n",
    "            raise ZeroDivisionError\n",
    "        \n",
    "    return divergence\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # List of amino acids\n",
    "    aas = list(\"ACDEFGHIKLMNPQRSTVWY*\") \n",
    "    n = 10000\n",
    "    \n",
    "    # Generate a random protein and some associated rna\n",
    "    protein = \"\".join(choice(aas, n))    \n",
    "    prot_to_rna = ProteinToRandomRNA()\n",
    "    rna = prot_to_rna.convert(protein)\n",
    "    \n",
    "    # Maybe check that converting back to protein results in the same sequence\n",
    "    print(f\"Conversion successful: {protein == rna_to_prot(rna)}\")\n",
    "    \n",
    "    # Calculate codon probabilities of the rna sequence\n",
    "    cp_predicted = codon_probabilities(rna)\n",
    "    \n",
    "    # Calculate codon probabilities based on the codon usage table\n",
    "    cp_orig = original_probs()\n",
    "    \n",
    "    # Create a completely random RNA sequence and get the codon probabilities\n",
    "    rand_rna = \"\".join(choice(list(\"ACGU\"), n*3))\n",
    "    cp_uniform = codon_probabilities(rand_rna)\n",
    "    \n",
    "    print(\"d(original || predicted) =\", kullback_leibler(cp_orig, cp_predicted))\n",
    "    print(\"d(predicted || original) =\", kullback_leibler(cp_predicted, cp_orig))\n",
    "    print()\n",
    "    print(\"d(original || uniform) =\", kullback_leibler(cp_orig, cp_uniform))\n",
    "    print(\"d(uniform || original) =\", kullback_leibler(cp_uniform, cp_orig))\n",
    "    print()\n",
    "    print(\"d(predicted || uniform) =\", kullback_leibler(cp_predicted, cp_uniform))\n",
    "    print(\"d(uniform || predicted) =\", kullback_leibler(cp_uniform, cp_predicted))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Conversion successful: True\n",
      "d(original || predicted) = 0.17034639645986455\n",
      "d(predicted || original) = 0.23257195163159272\n",
      "\n",
      "d(original || uniform) = 0.21584097867845167\n",
      "d(uniform || original) = 0.2847617723178679\n",
      "\n",
      "d(predicted || uniform) = 0.06128763267512392\n",
      "d(uniform || predicted) = 0.06234176121859636\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.557340Z",
     "start_time": "2019-07-08T22:04:23.539188Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "1. I first added one additional helper function to calculate the original datatable probabilities for each codon. I modified function get_probabability_dict to get the probabilities within all the codons, not just the specific amino acid.\n",
    "2. I finished the function codon_probabilities with the same sliding_window technique as in previous exercises\n",
    "3. For kullback_leibler function I first sorted the dictionaries for matching codons. I skipped all the entries where p probability was 0 and raised a ZeroDivisionError whenever q probability was zero.\n",
    "4. I completed the main function by using functions/methods from this and previous exercises. Solution itself is straightforward."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "\n",
    "Outputs are random and seem to be in the right ballpark.\n",
    "Output: \n",
    "\n",
    "Conversion successful: True\n",
    "d(original || predicted) = 0.17034639645986455\n",
    "d(predicted || original) = 0.23257195163159272\n",
    "\n",
    "d(original || uniform) = 0.21584097867845167\n",
    "d(uniform || original) = 0.2847617723178679\n",
    "\n",
    "d(predicted || uniform) = 0.06128763267512392\n",
    "d(uniform || predicted) = 0.06234176121859636"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Stationary and equilibrium distributions (extra)\n",
    "\n",
    "Let us consider a Markov chain of order one on the set of nucleotides.\n",
    "Its transition probabilities can be expressed as a $4 \\times 4$ matrix\n",
    "$P=(p_{ij})$, where the element $p_{ij}$ gives the probability of the $j$th nucleotide\n",
    "on the condition the previous nucleotide was the $i$th. An example of a transition matrix\n",
    "is\n",
    "\n",
    "\\begin{array}{l|rrrr}\n",
    " &     A &    C &     G &    T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.0 &  0.70 &  0.0 \\\\\n",
    "C &  0.00 &  0.4 &  0.00 &  0.6 \\\\\n",
    "G &  0.35 &  0.0 &  0.65 &  0.0 \\\\\n",
    "T &  0.00 &  0.2 &  0.00 &  0.8 \\\\\n",
    "\\end{array}.\n",
    "\n",
    "A distribution $\\pi=(\\pi_1,\\pi_2,\\pi_3,\\pi_4)$ is called *stationary*, if\n",
    "$\\pi = \\pi P$ (the product here is matrix product).\n",
    "\n",
    "20. Write function ```get_stationary_distributions``` that gets a transition matrix as parameter,\n",
    "  and returns the list of stationary distributions. You can do this with NumPy by\n",
    "  first taking transposition of both sides of the above equation to get equation\n",
    "  $\\pi^T = P^T \\pi^T$. Using numpy.linalg.eig take all eigenvectors related to\n",
    "  eigenvalue 1.0. By normalizing these vectors to sum up to one get the stationary distributions\n",
    "  of the original transition matrix. In the ```main``` function print the stationary distributions\n",
    "  of the above transition matrix."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "def get_stationary_distributions(transition):\n",
    "    \"\"\"\n",
    "    The function get a transition matrix of a degree one Markov chain as parameter.\n",
    "    It returns a list of stationary distributions, in vector form, for that chain.\n",
    "    \"\"\"\n",
    "    return np.random.rand(2, 4) - 0.5\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    transition=np.array([[0.3, 0, 0.7, 0],\n",
    "                         [0, 0.4, 0, 0.6],\n",
    "                         [0.35, 0, 0.65, 0],\n",
    "                         [0, 0.2, 0, 0.8]])\n",
    "    print(\"\\n\".join(\n",
    "        \", \".join(\n",
    "            f\"{pv:+.3f}\"\n",
    "            for pv in p) \n",
    "        for p in get_stationary_distributions(transition)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+0.058, -0.270, -0.416, -0.324\n",
      "-0.174, -0.460, +0.427, +0.248\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.591644Z",
     "start_time": "2019-07-08T22:04:23.580588Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "21. Implement the `kl_divergence` function below so that the main guarded code runs properly. Using your modified Markov chain generator generate a nucleotide sequence $s$ of length $10\\;000$. Choose prefixes of $s$ of lengths $1, 10, 100, 1000$, and $10\\;000$. For each of these prefixes find out their nucleotide distribution (of order 0) using your earlier tool. Use 1 as the pseudo count. Then, for each prefix, compute the KL divergence between the initial distribution and the normalized nucleotide distribution."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "def kl_divergences(initial, transition):\n",
    "    \"\"\"\n",
    "    Calculates the the Kullback-Leibler divergences between empirical distributions\n",
    "    generated using a markov model seeded with an initial distributin and a transition \n",
    "    matrix, and the initial distribution.\n",
    "    Sequences of length [1, 10, 100, 1000, 10000] are generated.\n",
    "    \"\"\"\n",
    "    return zip([1, 10, 100, 1000, 10000], np.random.rand(5))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition=np.array([[0.3, 0, 0.7, 0],\n",
    "                         [0, 0.4, 0, 0.6],\n",
    "                         [0.35, 0, 0.65, 0],\n",
    "                         [0, 0.2, 0, 0.8]])\n",
    "    print(\"Transition probabilities are:\")\n",
    "    print(transition)\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    print(\"Stationary distributions:\")\n",
    "    print(np.stack(stationary_distributions))\n",
    "    initial = stationary_distributions[1]\n",
    "    print(\"Using [{}] as initial distribution\\n\".format(\", \".join(f\"{v:.2f}\" for v in initial)))\n",
    "    results = kl_divergences(initial, transition)\n",
    "    for prefix_length, divergence in results: # iterate on prefix lengths in order (1, 10, 100...)\n",
    "        print(\"KL divergence of stationary distribution prefix \" \\\n",
    "              \"of length {:5d} is {:.8f}\".format(prefix_length, divergence))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.   0.7  0.  ]\n",
      " [0.   0.4  0.   0.6 ]\n",
      " [0.35 0.   0.65 0.  ]\n",
      " [0.   0.2  0.   0.8 ]]\n",
      "Stationary distributions:\n",
      "[[-0.07281989  0.24820398  0.28409077  0.12952854]\n",
      " [ 0.18375959  0.27218975 -0.18525085 -0.36823013]]\n",
      "Using [0.18, 0.27, -0.19, -0.37] as initial distribution\n",
      "\n",
      "KL divergence of stationary distribution prefix of length     1 is 0.79396509\n",
      "KL divergence of stationary distribution prefix of length    10 is 0.52119089\n",
      "KL divergence of stationary distribution prefix of length   100 is 0.77237298\n",
      "KL divergence of stationary distribution prefix of length  1000 is 0.56952726\n",
      "KL divergence of stationary distribution prefix of length 10000 is 0.27939748\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.635060Z",
     "start_time": "2019-07-08T22:04:23.618890Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "fill in"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "22. Implement the following in the ```main``` function.\n",
    "Find the stationary distribution for the following transition matrix:  \n",
    "\n",
    "\\begin{array}{ l | r r r r}\n",
    " & A &     C &     G &     T \\\\\n",
    "\\hline\n",
    "A &  0.30 &  0.10 &  0.50 &  0.10 \\\\\n",
    "C &  0.20 &  0.30 &  0.15 &  0.35 \\\\\n",
    "G &  0.25 &  0.15 &  0.20 &  0.40 \\\\\n",
    "T &  0.35 &  0.20 &  0.40 &  0.05 \\\\\n",
    "\\end{array}\n",
    "\n",
    "Since there is only one stationary distribution, it is called the *equilibrium distribution*.\n",
    "Choose randomly two nucleotide distributions. You can take these from your sleeve or\n",
    "sample them from the Dirichlet distribution. Then for each of these distributions\n",
    "as the initial distribution of the Markov chain, repeat the above experiment.\n",
    "\n",
    "The `main` function should return tuples, where the first element is the (random) initial distribution and the second element contains the results as a list of tuples where the first element is the kl divergence and the second element the empirical nucleotide distribution, for the different prefix lengths.\n",
    "\n",
    "The state distribution should converge to the equilibrium distribution no matter how we\n",
    "start the Markov chain! That is the last line of the tables should have KL-divergence very close to $0$ and an empirical distribution very close to the equilibrium distribution.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "def main(transition, equilibrium_distribution):\n",
    "    vals = list(zip(np.random.rand(10), np.random.rand(10, 4) - 0.5))\n",
    "    return zip(np.random.rand(2, 4) - 0.5, \n",
    "               [vals[:5], vals[5:]])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    transition = np.array([[0.3, 0.1, 0.5, 0.1],\n",
    "                           [0.2, 0.3, 0.15, 0.35],\n",
    "                           [0.25, 0.15, 0.2, 0.4],\n",
    "                           [0.35, 0.2, 0.4, 0.05]])\n",
    "    print(\"Transition probabilities are:\", transition, sep=\"\\n\")\n",
    "    stationary_distributions = get_stationary_distributions(transition)\n",
    "    # Uncomment the below line to check that there actually is only one stationary distribution\n",
    "    # assert len(stationary_distributions) == 1\n",
    "    equilibrium_distribution = stationary_distributions[0]\n",
    "    print(\"Equilibrium distribution:\")\n",
    "    print(equilibrium_distribution)\n",
    "    for initial_distribution, results in main(transition, equilibrium_distribution):\n",
    "        print(\"\\nUsing {} as initial distribution:\".format(initial_distribution))\n",
    "        print(\"kl-divergence   empirical distribution\")\n",
    "        print(\"\\n\".join(\"{:.11f}   {}\".format(di, kl) for di, kl in results))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Transition probabilities are:\n",
      "[[0.3  0.1  0.5  0.1 ]\n",
      " [0.2  0.3  0.15 0.35]\n",
      " [0.25 0.15 0.2  0.4 ]\n",
      " [0.35 0.2  0.4  0.05]]\n",
      "Equilibrium distribution:\n",
      "[-0.11630106 -0.21453487  0.25477777 -0.27808714]\n",
      "\n",
      "Using [-0.19790055  0.02681993  0.2868128  -0.37606765] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.44095917490   [-0.12044674  0.2314012  -0.13094703 -0.22516672]\n",
      "0.08392437825   [ 0.16744729 -0.48126008  0.04989796 -0.14773186]\n",
      "0.92283731075   [-0.4275764   0.42512138 -0.34646602  0.47872067]\n",
      "0.32526459671   [ 0.38364012  0.36920638  0.32403808 -0.08882104]\n",
      "0.66263412789   [ 0.14661419  0.09751009  0.32127799 -0.49361628]\n",
      "\n",
      "Using [ 0.35815848 -0.35243043  0.31368423 -0.42208417] as initial distribution:\n",
      "kl-divergence   empirical distribution\n",
      "0.89335466325   [ 0.05698383 -0.34208193  0.49568126  0.16266069]\n",
      "0.23779834143   [-0.16709767  0.42207763  0.17472058  0.42424352]\n",
      "0.51979675833   [ 0.36257971  0.43946894 -0.00766883 -0.44922222]\n",
      "0.94607910610   [-0.15114498  0.0056836  -0.343423    0.08304568]\n",
      "0.02624097880   [ 0.05623161 -0.39520592  0.34428786 -0.01300323]\n"
     ]
    }
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-08T22:04:23.681300Z",
     "start_time": "2019-07-08T22:04:23.657345Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Idea of solution\n",
    "\n",
    "fill in"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Discussion\n",
    "fill in"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "598.85px",
    "left": "1223px",
    "right": "20px",
    "top": "121px",
    "width": "353px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "interpreter": {
   "hash": "dca0ade3e726a953b501b15e8e990130d2b7799f14cfd9f4271676035ebe5511"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}